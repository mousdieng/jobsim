# Testing Without Spending Money

## Quick Start (FREE Testing)

### 1. Set Up Mock Provider

Edit `ai-engine/.env`:
```bash
AI_PROVIDER=mock
```

That's it! No API keys needed.

### 2. Start the Server

```bash
cd ai-engine
npm run dev
```

You should see:
```
‚ö†Ô∏è  MOCK MODE ENABLED - No API calls will be made
‚ö†Ô∏è  This is for testing only. Returns realistic sample data.
‚úÖ Configuration validated. Using MOCK as AI provider
```

### 3. Test All Endpoints

#### Generate Tasks (FREE)
```bash
curl -X POST http://localhost:3001/api/tasks/generate \
  -H "Content-Type: application/json" \
  -d '{
    "job_field": "software_engineering",
    "difficulty_level": "intermediate",
    "count": 2
  }'
```

**Response:** Realistic task data generated instantly, $0 cost!

#### Generate Meeting (FREE)
```bash
curl -X POST http://localhost:3001/api/meetings/generate \
  -H "Content-Type: application/json" \
  -d '{
    "task_id": "test-123",
    "meeting_type": "kickoff",
    "task_title": "Build REST API",
    "task_description": "Create a RESTful API for user management",
    "user_name": "Test User",
    "user_role": "Developer"
  }'
```

**Response:** Complete meeting with participants, agenda, transcript, $0 cost!

#### Evaluate Submission (FREE)
```bash
curl -X POST http://localhost:3001/api/evaluations/quick-score \
  -H "Content-Type: application/json" \
  -d '{
    "content": "I completed the task by implementing all required features...",
    "criteria": ["Quality", "Completeness"]
  }'
```

**Response:** Detailed evaluation with scores, $0 cost!

---

## What the Mock Provider Does

### Returns Realistic Data
- **Tasks**: Complete with deliverables, resources, skills required
- **Meetings**: Full participants, agendas, transcripts, action items
- **Evaluations**: Detailed scoring with feedback and recommendations

### Smart Detection
The mock provider analyzes your request and returns appropriate data:
- Detects job field from request ‚Üí Uses relevant skills
- Detects difficulty level ‚Üí Adjusts task complexity
- Detects meeting type ‚Üí Creates appropriate scenario
- Parses evaluation criteria ‚Üí Provides relevant feedback

### Example Task Output (Mock)
```json
{
  "tasks": [{
    "title": "Software Engineering Task 1",
    "description": "This is a comprehensive intermediate-level task...",
    "job_field": "software_engineering",
    "difficulty_level": "intermediate",
    "estimated_duration": "4-8 hours",
    "skills_required": ["JavaScript", "TypeScript", "Problem Solving", "Debugging", "Testing"],
    "deliverables": [...],
    "resources": [...],
    "tags": ["software_engineering", "intermediate", "professional", "simulation"]
  }]
}
```

### Example Evaluation Output (Mock)
```json
{
  "overall_score": 82,
  "letter_grade": "B+",
  "criteria_breakdown": [
    {
      "criterion": "Completeness",
      "weight": 0.25,
      "score": 22,
      "max_score": 25,
      "feedback": "The submission addresses most required elements..."
    }
  ],
  "strengths": ["Clear presentation", "Good understanding", "Professional style"],
  "areas_for_improvement": ["Add more detail", "Deeper analysis"],
  "detailed_feedback": "This submission demonstrates solid understanding...",
  "recommendations": [...]
}
```

---

## Testing Workflow

### Phase 1: Mock Provider (FREE)
1. ‚úÖ Test all API endpoints
2. ‚úÖ Verify request/response formats
3. ‚úÖ Build and test your frontend integration
4. ‚úÖ Test error handling
5. ‚úÖ Develop features without costs

**Cost: $0.00**

### Phase 2: Real AI Testing (PAID)
Once your integration works with mock data:

1. Switch to real AI provider:
```bash
# Option 1: Claude (cheaper)
AI_PROVIDER=claude
ANTHROPIC_API_KEY=sk-ant-your-key

# Option 2: OpenAI
AI_PROVIDER=openai
OPENAI_API_KEY=sk-your-key
```

2. Test with small samples (1-2 requests)
3. Compare quality
4. Choose your provider

**Cost: ~$0.10 for testing**

---

## Features of Mock Provider

### ‚úÖ Advantages
- **FREE**: No API costs
- **FAST**: Instant responses (500ms simulated delay)
- **REALISTIC**: Production-quality test data
- **RELIABLE**: No API rate limits or errors
- **OFFLINE**: Works without internet
- **SAFE**: No accidental API spending

### ‚ö†Ô∏è Limitations
- **Not Real AI**: Same data pattern repeated
- **No Learning**: Doesn't improve with feedback
- **Limited Variety**: Generates similar outputs
- **Testing Only**: Not for production use

---

## Switching Between Providers

### During Development
```bash
AI_PROVIDER=mock  # Free testing
```

### Quality Testing
```bash
AI_PROVIDER=claude  # Cheaper real AI
```

### Production
```bash
AI_PROVIDER=claude  # or openai based on preference
```

Just change the variable and restart!

---

## Cost Savings Example

**Typical Development Cycle:**

Without Mock Provider:
- Testing: 50 requests √ó $0.20 = **$10.00**
- Development: 200 requests √ó $0.20 = **$40.00**
- Debugging: 100 requests √ó $0.20 = **$20.00**
- **Total: $70.00**

With Mock Provider:
- Testing: 50 requests √ó $0.00 = **$0.00**
- Development: 200 requests √ó $0.00 = **$0.00**
- Debugging: 100 requests √ó $0.00 = **$0.00**
- Final testing: 10 real requests √ó $0.20 = **$2.00**
- **Total: $2.00**

**Savings: $68.00 (97% reduction)**

---

## Testing Tips

### 1. Test All Job Fields
```bash
# Software Engineering
{"job_field": "software_engineering", ...}

# Marketing
{"job_field": "marketing", ...}

# Data Science
{"job_field": "data_science", ...}
```

### 2. Test All Difficulty Levels
```bash
{"difficulty_level": "beginner"}
{"difficulty_level": "intermediate"}
{"difficulty_level": "advanced"}
{"difficulty_level": "expert"}
```

### 3. Test All Meeting Types
```bash
{"meeting_type": "kickoff"}
{"meeting_type": "standup"}
{"meeting_type": "review"}
{"meeting_type": "client_call"}
```

### 4. Test Error Cases
Mock provider handles edge cases gracefully!

---

## Comparison Table

| Feature | Mock | Claude | OpenAI |
|---------|------|--------|--------|
| **Cost** | FREE | $0.08/task | $0.20/task |
| **Speed** | 0.5s | 2-5s | 3-8s |
| **Quality** | Fixed | High | High |
| **Variety** | Low | High | High |
| **Development** | ‚úÖ Perfect | ‚ùå Expensive | ‚ùå Expensive |
| **Production** | ‚ùå Not suitable | ‚úÖ Good | ‚úÖ Good |
| **Testing** | ‚úÖ Perfect | ‚ö†Ô∏è Costs money | ‚ö†Ô∏è Costs money |

---

## When to Use Each Provider

### Use Mock When:
- üîß **Developing** new features
- üß™ **Testing** integration
- üêõ **Debugging** issues
- üìö **Learning** the API
- üí∞ **Saving** money

### Use Claude When:
- ‚ú® **Quality testing** needed
- üí∞ **Cost-conscious** production
- üìä **High volume** generation
- üéØ **Production** use

### Use OpenAI When:
- üèÜ **Absolute best** quality needed
- üíº **Already using** OpenAI
- üîí **Specific** GPT-4 requirements

---

## Next Steps

1. ‚úÖ Set `AI_PROVIDER=mock` in `.env`
2. ‚úÖ Start server: `npm run dev`
3. ‚úÖ Test all endpoints (see examples above)
4. ‚úÖ Build your frontend integration
5. ‚úÖ Test thoroughly for FREE
6. ‚è≥ Switch to real AI when ready

**Happy Testing! üöÄ**
